# üîç Predicci√≥n de Churn de Clientes

Este proyecto de machine learning tiene como objetivo predecir la p√©rdida de clientes (*churn*) en una empresa utilizando modelos de clasificaci√≥n. Se aplican t√©cnicas de preprocesamiento, balanceo de clases, entrenamiento de modelos y comparaci√≥n de m√©tricas para identificar la mejor soluci√≥n predictiva.


## üìÅ Estructura del Proyecto
‚îú‚îÄ‚îÄ churn_prediction.ipynb # Notebook principal del an√°lisis
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îî‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv 
‚îú‚îÄ‚îÄ notebook/
‚îÇ ‚îî‚îÄ‚îÄ Prediccion_churn_clientes.ipynb 
‚îî‚îÄ‚îÄ README.md 


## üß† Objetivos del Proyecto

- Analizar un conjunto de datos de clientes y su comportamiento.
- Preprocesar y balancear los datos para abordar el problema de clases desbalanceadas.
- Evaluar distintos modelos de clasificaci√≥n:
  - Regresi√≥n Log√≠stica
  - Random Forest
  - XGBoost
- Comparar el desempe√±o de los modelos con y sin t√©cnicas de balanceo (`class_weight`, SMOTE).
- Extraer conclusiones basadas en m√©tricas de clasificaci√≥n.



## üõ†Ô∏è Librer√≠as

- Pandas, NumPy
- Scikit-learn
- XGBoost
- imbalanced-learn
- Matplotlib, Seaborn



## üìä Comparativa de Modelos

| Modelo                       | Accuracy | Precision | Recall | F1-score |
|-----------------------------|----------|-----------|--------|----------|
| Reg. Log√≠stica              | 0.806    | 0.656     | 0.567  | 0.608    |
| Reg. Log√≠stica (balanced)   | 0.737    | 0.504     | 0.795  | 0.617    |
| Reg. Log√≠stica + SMOTE      | 0.745    | 0.514     | 0.740  | 0.606    |
| Random Forest               | 0.787    | 0.628     | 0.488  | 0.550    |
| Random Forest + SMOTE       | 0.759    | 0.542     | 0.611  | 0.575    |
| XGBoost                     | 0.780    | 0.603     | 0.508  | 0.551    |
| XGBoost + SMOTE             | 0.764    | 0.548     | 0.645  | 0.593    |


## üîé Evaluaci√≥n de Resultados

- **Modelos sin balanceo**, como la regresi√≥n log√≠stica original, obtienen mayor **accuracy**, pero sacrifican recall, que es clave en problemas de churn.
- **Modelos balanceados**, como `class_weight` o SMOTE, **aumentan significativamente el recall**, lo que permite identificar mejor a los clientes que abandonan, aunque a costa de una leve p√©rdida de precisi√≥n.
- **Conclusi√≥n**: si el objetivo del negocio es **anticipar el abandono** de la mayor√≠a de los clientes posibles, el modelo m√°s recomendable es la **regresi√≥n log√≠stica balanceada** o con SMOTE, debido a su alto **recall y F1-score**, aun cuando su accuracy no sea el m√°s alto.


